{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Serializing Models with TensorFlow Keras\n",
    "Source: https://www.tensorflow.org/alpha/guide/keras/saving_and_serializing#weights-only_saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1 : Saving and Serialization for Sequential Models and Functional API.\n",
    "\n",
    "\n",
    "Part 2 : Saving for Custom subclass of models. The API is slightly different to Sequential or Functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Saving Sequential models or Functional models\n",
    "\n",
    "\n",
    "Let's consider the following model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3_layer_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 - 7s - loss: 0.1413\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop())\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1,\n",
    "                   verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole-model saving\n",
    "\n",
    "This file includes:\n",
    "\n",
    "- The model's architecture\n",
    "- The model's weight values (which were learned during training)\n",
    "- The model's training config (what you passed to compile), if any\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left off)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('path_to_my_model.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to SavedModel\n",
    "\n",
    "SavedModel is a standalone serialization format for Tensorflow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0322 05:26:37.342111 19832 deprecation.py:323] From c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0322 05:26:37.354104 19832 tf_logging.py:161] Export includes no default signature!\n",
      "W0322 05:26:39.856304 19832 tf_logging.py:161] Export includes no default signature!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=1e-07, atol=1e-06\n\nMismatch: 79.8%\nMax absolute difference: 0.97171205\nMax relative difference: 764597.3\n x: array([[1.226035e-05, 1.667942e-08, 8.437489e-05, ..., 9.975024e-01,\n        1.408940e-05, 9.716916e-04],\n       [6.980557e-05, 1.912783e-04, 9.979590e-01, ..., 2.244759e-06,...\n y: array([[2.332846e-05, 3.303864e-08, 1.091335e-04, ..., 9.975899e-01,\n        3.049750e-06, 7.981198e-04],\n       [1.767552e-07, 2.149919e-04, 9.997712e-01, ..., 1.167043e-07,...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9fc86c5013b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Check that the state is preserved\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnew_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Note that the optimizer state is preserved as well:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[1;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[0;32m   1491\u001b[0m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Not equal to tolerance rtol=%g, atol=%g'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0matol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[1;32m-> 1493\u001b[1;33m                          verbose=verbose, header=header, equal_nan=equal_nan)\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[0;32m    817\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=1e-07, atol=1e-06\n\nMismatch: 79.8%\nMax absolute difference: 0.97171205\nMax relative difference: 764597.3\n x: array([[1.226035e-05, 1.667942e-08, 8.437489e-05, ..., 9.975024e-01,\n        1.408940e-05, 9.716916e-04],\n       [6.980557e-05, 1.912783e-04, 9.979590e-01, ..., 2.244759e-06,...\n y: array([[2.332846e-05, 3.303864e-08, 1.091335e-04, ..., 9.975899e-01,\n        3.049750e-06, 7.981198e-04],\n       [1.767552e-07, 2.149919e-04, 9.997712e-01, ..., 1.167043e-07,..."
     ]
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "keras.experimental.export_saved_model(model, 'path_to_saved_model')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = keras.experimental.load_from_saved_model('path_to_saved_model')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SavedModel files that were created contain:\n",
    "\n",
    "- A TensorFlow checkpoint containing the model weights.\n",
    "- A SavedModel proto containing the underlying Tensorflow graph. Separate graphs are saved for prediction (serving), train, and evaluation. If the model wasn't compiled before, then only the inference graph gets exported.\n",
    "- The model's architecture config, if available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture-only saving\n",
    "\n",
    "In this case, you can retrieve the \"config\" of the model via the `get_config()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "reinitialized_model = keras.Model.from_config(config)\n",
    "\n",
    "# Note that the model state is not preserved! We only saved the architecture.\n",
    "new_predictions = reinitialized_model.predict(x_test)\n",
    "assert abs(np.sum(predictions - new_predictions)) > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively use `to_json()` and `from_json()`, which uses a JSON string to store the config instead of a Python dict. This is useful to save the config to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_config = model.to_json()\n",
    "reinitialized_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights-only saving\n",
    "\n",
    "In this case, you can retrieve the weights values as a list of Numpy arrays via `get_weights()`, and set the state of the model via `set_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()  # Retrieves the state of the model.\n",
    "model.set_weights(weights)  # Sets the state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simplest, recommended way is just this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "del model\n",
    "model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights-only saving in SavedModel format\n",
    "\n",
    "Anything  else defaults to SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_savedmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For total explicitness, the format can be explicitly passed via the save_format argument, which can take the value \"tf\" or \"h5\":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_savedmodel', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Subclassed Models\n",
    "\n",
    "Sequential models and Functional models are datastructures that represent a DAG of layers. As such, they can be safely serialized and deserialized.\n",
    "\n",
    "A subclassed model differs in that it's not a datastructure, it's a piece of code. The architecture of the model is defined via the body of the call method. This means that the architecture of the model cannot be safely serialized. To load a model, you'll need to have access to the code that created it (the code of the model subclass). Alternatively, you could be serializing this code as bytecode (e.g. via pickling), but that's unsafe and generally not portable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's consider the following subclassed model, which follows the same structure as the model from the first section:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerMLP(keras.Model):\n",
    "  \n",
    "  def __init__(self, name=None):\n",
    "    super(ThreeLayerMLP, self).__init__(name=name)\n",
    "    self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\n",
    "    self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')\n",
    "    self.pred_layer = layers.Dense(10, activation='softmax', name='predictions')\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    x = self.dense_1(inputs)\n",
    "    x = self.dense_2(x)\n",
    "    return self.pred_layer(x)\n",
    "\n",
    "def get_model():\n",
    "  return ThreeLayerMLP(name='3_layer_mlp')\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, a subclassed model that has never been used cannot be saved.\n",
    "\n",
    "Always runt he code alteast once before saving. \n",
    "\n",
    "Let's train teh model,so as to give it a state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 9s 142us/sample - loss: 0.3048\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop())\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using save_weights\n",
    "model.save_weights('path_to_my_weights', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Also save the loss on the first batch\n",
    "# to later assert that the optimizer state was preserved\n",
    "\n",
    "first_batch_loss = model.train_on_batch(x_train[:64], y_train[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To restore your model, you will need access to the code that created the model object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model\n",
    "new_model = get_model()\n",
    "new_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop())\n",
    "\n",
    "# This initializes the variables used by the optimizers,\n",
    "# as well as any stateful metric variables\n",
    "new_model.train_on_batch(x_train[:1], y_train[:1])\n",
    "\n",
    "# Load the state of the old model\n",
    "new_model.load_weights('path_to_my_weights')\n",
    "\n",
    "# Check that the model state has been preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, atol=1e-6)\n",
    "\n",
    "# The optimizer state is preserved as well,\n",
    "# so you can resume training where you left off\n",
    "new_first_batch_loss = new_model.train_on_batch(x_train[:64], y_train[:64])\n",
    "assert first_batch_loss == new_first_batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
