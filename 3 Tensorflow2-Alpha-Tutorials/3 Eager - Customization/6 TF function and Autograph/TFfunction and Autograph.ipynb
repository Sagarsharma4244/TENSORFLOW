{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.function\n",
    "Source: https://www.tensorflow.org/alpha/tutorials/eager/tf_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.0.0-alpha0\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=16, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 2.],\n",
       "       [2., 2.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A function is like an op\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add(tf.ones([2, 2]), tf.ones([2, 2]))  #  [[2., 2.], [2., 2.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tf.function you define is just like a core TensorFlow operation: you can execute it eagerly, you can use it in a graph, it has gradients, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=44, shape=(), dtype=float32, numpy=1.0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions have gradients\n",
    "\n",
    "@tf.function\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "with tf.GradientTape() as tape:\n",
    "  result = add(v, 1.0)\n",
    "tape.gradient(result, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=74, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[3., 3.],\n",
       "       [3., 3.],\n",
       "       [3., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use functions inside functions\n",
    "\n",
    "@tf.function\n",
    "def dense_layer(x, w, b):\n",
    "  return add(tf.matmul(x, w), b)\n",
    "\n",
    "dense_layer(tf.ones([3, 2]), tf.ones([2, 2]), tf.ones([2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymorphism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.function tries to be as generic as a Python function.\n",
    "You can call Python functions with all sorts of signatures, and Python will usually do something reasonable. tf.function does this type of polymorphism for you even though the underlying TensorFlow graphs it generates are specific to the particular types in its signature.\n",
    "\n",
    "You can call a function with arguments of different types to see what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 tf.Tensor(2, shape=(), dtype=int32)\n",
      "add 1.1 tf.Tensor(2.2, shape=(), dtype=float32)\n",
      "add string tensor tf.Tensor(b'aa', shape=(), dtype=string)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104, shape=(), dtype=string, numpy=b'aa'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions are polymorphic\n",
    "\n",
    "@tf.function\n",
    "def add(a):\n",
    "  return a + a\n",
    "\n",
    "print(\"add 1\", add(1))\n",
    "print(\"add 1.1\", add(1.1))\n",
    "print(\"add string tensor\", add(tf.constant(\"a\")))\n",
    "c = add.get_concrete_function(tf.TensorSpec(shape=None, dtype=tf.string))\n",
    "c(a=tf.constant(\"a\"))  # aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 3.617294017908095\n",
      "Function conv: 2.0063116591468\n",
      "Note how there's not much difference in performance for convolutions\n",
      "eager lstm: 0.14929981073746657\n",
      "function lstm: 0.012622805108856383\n"
     ]
    }
   ],
   "source": [
    "# Functions can be faster than eager code, for graphs with many small ops\n",
    "\n",
    "import timeit\n",
    "conv_layer = tf.keras.layers.Conv2D(100, 3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "  return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1, 200, 200, 100])\n",
    "# warm up\n",
    "conv_layer(image); conv_fn(image)\n",
    "print(\"Eager conv:\", timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")\n",
    "\n",
    "lstm_cell = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "  return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10, 10])\n",
    "state = [tf.zeros([10, 10])] * 2\n",
    "# warm up\n",
    "lstm_cell(input, state); lstm_fn(input, state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State in tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1610, shape=(), dtype=float32, numpy=10.0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatic control dependencies\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(2.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x, y):\n",
    "  a.assign(y * b)\n",
    "  b.assign_add(x * a)\n",
    "  return a + b\n",
    "\n",
    "f(1.0, 2.0)  # 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.function-decorated function tried to create variables on non-first call.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4da9e65c12dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Note: BROKEN, will throw exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_canonicalize_function_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1285\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1287\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1288\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1578\u001b[0m           or call_context_key not in self._function_cache.missed):\n\u001b[0;32m   1579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1581\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   1513\u001b[0m         self._function_attributes)\n\u001b[0;32m   1514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    692\u001b[0m                                           converted_func)\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, IndexedSlices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m                   \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                   \u001b[0mforce_conversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m               ), args, kwargs)\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;31m# Wrapping around a decorator allows checks like tf_inspect.getargspec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m   \u001b[1;31m# The converted function's closure is simply inserted into the function's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\tmp8qylcdb1.py\u001b[0m in \u001b[0;36mtf__f\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m   \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Variable'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m   \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'assign_add'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_decorators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefun_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_convert\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_conversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, owner, options, args, kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Permanently whitelisted: %s: constructor'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m   \u001b[1;31m# Other built-in modules are permanently whitelisted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__self__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[1;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mgetter\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;34m\"\"\"To avoid capturing loop variables.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36minvalid_creator_scope\u001b[1;34m(*unused_args, **unused_kwds)\u001b[0m\n\u001b[0;32m    373\u001b[0m       \u001b[1;34m\"\"\"Disables variable creation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m       raise ValueError(\n\u001b[1;32m--> 375\u001b[1;33m           \u001b[1;34m\"tf.function-decorated function tried to create \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m           \"variables on non-first call.\")\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: tf.function-decorated function tried to create variables on non-first call."
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "    v = tf.Variable(1.0)\n",
    "    v.assign_add(x)\n",
    "    return v\n",
    "\n",
    "f(1.) # Note: BROKEN, will throw exception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-ambiguous code is ok though\n",
    "\n",
    "v = tf.Variable(1.0)\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "  return v.assign_add(x)\n",
    "\n",
    "f(1.0)  # 2.0\n",
    "f(2.0)  # 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control flow and autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0860520601 0.272780418 0.211995602 ... 0.188304186 0.558368802 0.296167374]\n",
      "[0.0858402774 0.266210109 0.20887582 ... 0.186109632 0.5067662 0.287801325]\n",
      "[0.0856300518 0.260094821 0.205890208 ... 0.183990225 0.46742174 0.280109912]\n",
      "[0.085421361 0.25438422 0.203029424 ... 0.181941777 0.436113775 0.273006797]\n",
      "[0.0852141902 0.249035433 0.200284928 ... 0.1799604 0.410417974 0.266420424]\n",
      "[0.0850085169 0.244011715 0.197649121 ... 0.178042516 0.388827533 0.260290891]\n",
      "[0.0848043337 0.239281386 0.195114955 ... 0.176184788 0.370349 0.254567593]\n",
      "[0.0846016183 0.234816864 0.192676052 ... 0.174384132 0.354296923 0.249207422]\n",
      "[0.0844003484 0.230594084 0.190326616 ... 0.172637701 0.340180755 0.244173452]\n",
      "[0.0842005 0.226591989 0.188061267 ... 0.170942813 0.327638716 0.239433855]\n",
      "[0.0840020701 0.222791955 0.185875118 ... 0.16929695 0.316397429 0.234960914]\n",
      "[0.0838050395 0.219177485 0.183763623 ... 0.167697847 0.306245834 0.230730489]\n",
      "[0.0836093873 0.21573393 0.181722671 ... 0.166143283 0.297017932 0.226721391]\n",
      "[0.0834151 0.212448224 0.179748371 ... 0.164631233 0.288581252 0.222914919]\n",
      "[0.0832221583 0.209308639 0.177837193 ... 0.163159817 0.280828446 0.219294548]\n",
      "[0.0830305517 0.20630464 0.175985828 ... 0.161727235 0.273671627 0.21584557]\n",
      "[0.0828402638 0.203426734 0.174191236 ... 0.160331786 0.267037958 0.212554842]\n",
      "[0.0826512799 0.200666308 0.172450557 ... 0.158971906 0.260866493 0.209410593]\n",
      "[0.0824635774 0.198015571 0.170761138 ... 0.157646105 0.255105793 0.206402272]\n",
      "[0.0822771564 0.195467442 0.169120505 ... 0.156352982 0.249712124 0.203520328]\n",
      "[0.0820919946 0.193015456 0.167526349 ... 0.155091226 0.244648024 0.200756133]\n",
      "[0.0819080696 0.190653712 0.165976509 ... 0.153859586 0.239881143 0.198101878]\n",
      "[0.0817253813 0.188376784 0.164468989 ... 0.152656853 0.235383466 0.195550442]\n",
      "[0.0815439075 0.186179727 0.16300188 ... 0.151481941 0.231130511 0.193095341]\n",
      "[0.0813636407 0.184057951 0.161573395 ... 0.150333792 0.227100819 0.190730676]\n",
      "[0.081184566 0.182007253 0.160181895 ... 0.149211407 0.223275468 0.188451]\n",
      "[0.0810066685 0.18002376 0.158825815 ... 0.148113802 0.219637722 0.186251357]\n",
      "[0.0808299333 0.178103864 0.15750365 ... 0.147040114 0.21617271 0.184127137]\n",
      "[0.0806543529 0.176244229 0.156214014 ... 0.145989478 0.212867171 0.182074144]\n",
      "[0.0804799125 0.17444177 0.154955596 ... 0.144961074 0.209709197 0.18008849]\n",
      "[0.0803066 0.17269361 0.153727144 ... 0.143954143 0.206688106 0.178166538]\n",
      "[0.0801344 0.170997083 0.152527511 ... 0.142967924 0.203794286 0.176304951]\n",
      "[0.0799633041 0.1693497 0.151355565 ... 0.142001733 0.201019019 0.174500644]\n",
      "[0.0797933 0.167749092 0.150210261 ... 0.141054899 0.198354423 0.172750741]\n",
      "[0.0796243697 0.166193128 0.149090618 ... 0.14012678 0.195793331 0.171052545]\n",
      "[0.0794565156 0.164679736 0.147995681 ... 0.139216766 0.193329185 0.169403568]\n",
      "[0.0792897195 0.163207039 0.14692454 ... 0.138324261 0.190956011 0.16780144]\n",
      "[0.0791239738 0.161773205 0.145876378 ... 0.137448728 0.18866834 0.16624403]\n",
      "[0.0789592564 0.160376593 0.144850343 ... 0.136589631 0.186461151 0.164729267]\n",
      "[0.0787955597 0.159015581 0.143845692 ... 0.135746479 0.184329852 0.16325523]\n",
      "[0.0786328837 0.157688707 0.142861679 ... 0.134918764 0.182270139 0.161820158]\n",
      "[0.0784712136 0.156394556 0.141897634 ... 0.134106025 0.180278093 0.16042231]\n",
      "[0.0783105269 0.155131802 0.14095287 ... 0.133307815 0.178350121 0.15906015]\n",
      "[0.0781508312 0.153899178 0.140026748 ... 0.132523715 0.176482826 0.157732159]\n",
      "[0.077992104 0.152695537 0.139118671 ... 0.131753296 0.17467311 0.156436935]\n",
      "[0.0778343529 0.151519731 0.138228044 ... 0.130996168 0.172918037 0.155173153]\n",
      "[0.0776775479 0.150370717 0.137354329 ... 0.130251959 0.171214953 0.15393956]\n",
      "[0.0775216892 0.149247497 0.136497 ... 0.129520312 0.169561297 0.15273498]\n",
      "[0.0773667544 0.148149118 0.135655552 ... 0.128800869 0.167954728 0.15155828]\n",
      "[0.0772127509 0.147074685 0.134829491 ... 0.128093302 0.166393057 0.150408387]\n",
      "[0.0770596638 0.146023303 0.134018362 ... 0.127397284 0.164874241 0.149284333]\n",
      "[0.0769074932 0.144994199 0.133221716 ... 0.126712486 0.163396329 0.148185149]\n",
      "[0.0767562166 0.143986583 0.132439122 ... 0.126038626 0.161957547 0.147109911]\n",
      "[0.0766058266 0.142999709 0.131670177 ... 0.125375435 0.160556167 0.146057785]\n",
      "[0.0764563158 0.142032877 0.130914465 ... 0.124722593 0.159190625 0.14502795]\n",
      "[0.0763076842 0.141085401 0.130171657 ... 0.124079868 0.157859385 0.144019619]\n",
      "[0.0761599168 0.140156671 0.129441351 ... 0.123446979 0.156561047 0.143032074]\n",
      "[0.0760130063 0.139246076 0.128723204 ... 0.122823678 0.155294284 0.142064586]\n",
      "[0.0758669376 0.138353035 0.128016919 ... 0.122209743 0.154057816 0.141116485]\n",
      "[0.0757217109 0.137476966 0.127322122 ... 0.121604927 0.152850464 0.140187144]\n",
      "[0.0755773187 0.136617348 0.126638532 ... 0.121009022 0.151671112 0.139275953]\n",
      "[0.0754337385 0.135773689 0.125965849 ... 0.120421797 0.150518671 0.138382316]\n",
      "[0.0752909705 0.134945482 0.12530379 ... 0.119843051 0.149392143 0.137505695]\n",
      "[0.075149022 0.134132266 0.12465208 ... 0.119272582 0.148290589 0.136645541]\n",
      "[0.0750078708 0.133333579 0.124010444 ... 0.11871019 0.147213086 0.13580136]\n",
      "[0.0748675 0.132549018 0.123378612 ... 0.118155688 0.146158755 0.134972647]\n",
      "[0.0747279301 0.131778166 0.122756347 ... 0.11760889 0.145126805 0.134158939]\n",
      "[0.0745891333 0.13102062 0.122143418 ... 0.117069609 0.144116417 0.133359805]\n",
      "[0.0744511113 0.130276009 0.121539585 ... 0.116537698 0.143126875 0.132574782]\n",
      "[0.0743138492 0.12954396 0.120944627 ... 0.116012976 0.14215748 0.131803483]\n",
      "[0.0741773471 0.12882413 0.12035834 ... 0.115495279 0.141207546 0.131045505]\n",
      "[0.0740415901 0.128116176 0.119780496 ... 0.11498446 0.140276417 0.130300462]\n",
      "[0.0739065707 0.12741977 0.119210906 ... 0.114480354 0.139363497 0.129568011]\n",
      "[0.0737723 0.126734614 0.118649378 ... 0.113982834 0.138468176 0.128847763]\n",
      "[0.0736387447 0.126060411 0.118095711 ... 0.113491744 0.137589931 0.128139421]\n",
      "[0.0735059157 0.125396863 0.117549732 ... 0.113006957 0.136728212 0.127442643]\n",
      "[0.0733738095 0.124743707 0.117011264 ... 0.112528339 0.135882512 0.12675713]\n",
      "[0.073242411 0.124100655 0.116480127 ... 0.112055756 0.135052323 0.126082569]\n",
      "[0.0731117129 0.123467453 0.115956157 ... 0.111589089 0.134237185 0.125418678]\n",
      "[0.0729817152 0.122843862 0.115439221 ... 0.111128196 0.133436635 0.124765158]\n",
      "[0.0728524104 0.122229628 0.11492914 ... 0.110672981 0.132650256 0.12412177]\n",
      "[0.072723791 0.121624529 0.114425771 ... 0.110223308 0.131877631 0.12348824]\n",
      "[0.0725958496 0.121028341 0.113928966 ... 0.10977909 0.131118372 0.122864336]\n",
      "[0.0724685863 0.120440833 0.113438569 ... 0.109340198 0.130372092 0.122249797]\n",
      "[0.072341986 0.119861811 0.112954468 ... 0.10890653 0.129638419 0.121644408]\n",
      "[0.0722160488 0.11929106 0.112476513 ... 0.108477987 0.128917009 0.121047914]\n",
      "[0.0720907673 0.118728399 0.112004578 ... 0.108054452 0.128207535 0.120460115]\n",
      "[0.071966134 0.118173636 0.111538544 ... 0.107635863 0.127509654 0.119880825]\n",
      "[0.0718421489 0.117626578 0.111078277 ... 0.107222095 0.126823068 0.119309813]\n",
      "[0.0717188 0.117087059 0.110623673 ... 0.106813066 0.126147464 0.118746884]\n",
      "[0.0715960786 0.116554901 0.110174604 ... 0.1064087 0.125482544 0.118191853]\n",
      "[0.0714739859 0.116029933 0.109730966 ... 0.10600888 0.124828041 0.117644548]\n",
      "[0.0713525191 0.115512013 0.109292649 ... 0.105613537 0.124183685 0.117104784]\n",
      "[0.0712316632 0.115000971 0.108859546 ... 0.105222598 0.123549208 0.116572395]\n",
      "[0.0711114258 0.114496648 0.108431563 ... 0.104835972 0.122924373 0.116047204]\n",
      "[0.0709917918 0.113998912 0.108008578 ... 0.104453571 0.12230894 0.115529053]\n",
      "[0.0708727613 0.113507621 0.107590519 ... 0.104075335 0.121702656 0.115017787]\n",
      "[0.0707543343 0.113022633 0.10717728 ... 0.103701174 0.121105321 0.114513256]\n",
      "[0.0706364959 0.112543814 0.106768757 ... 0.103331037 0.120516688 0.114015304]\n",
      "[0.0705192462 0.11207103 0.106364883 ... 0.102964826 0.119936563 0.113523804]\n",
      "[0.0704025701 0.111604162 0.10596557 ... 0.102602482 0.119364761 0.113038599]\n",
      "[0.0702864751 0.111143082 0.105570719 ... 0.102243938 0.11880105 0.112559587]\n",
      "[0.0701709539 0.110687681 0.105180241 ... 0.101889133 0.118245259 0.112086616]\n",
      "[0.070056 0.110237822 0.104794078 ... 0.101537995 0.117697217 0.111619554]\n",
      "[0.0699416101 0.10979341 0.104412138 ... 0.101190478 0.117156729 0.111158296]\n",
      "[0.0698277801 0.10935434 0.104034342 ... 0.100846492 0.116623618 0.110702701]\n",
      "[0.0697145 0.108920507 0.103660621 ... 0.100505993 0.116097726 0.110252678]\n",
      "[0.0696017742 0.108491793 0.103290908 ... 0.100168936 0.115578905 0.109808102]\n",
      "[0.0694895908 0.108068109 0.102925122 ... 0.0998352394 0.115066975 0.109368853]\n",
      "[0.0693779439 0.107649349 0.102563202 ... 0.0995048583 0.114561796 0.10893485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0692668408 0.107235432 0.10220506 ... 0.0991777405 0.114063218 0.108505964]\n",
      "[0.0691562742 0.106826261 0.101850659 ... 0.0988538265 0.1135711 0.108082123]\n",
      "[0.0690462291 0.106421739 0.10149993 ... 0.0985330716 0.113085307 0.107663207]\n",
      "[0.0689367056 0.106021777 0.101152785 ... 0.0982154161 0.112605691 0.107249118]\n",
      "[0.0688277 0.1056263 0.100809187 ... 0.0979008153 0.112132132 0.106839776]\n",
      "[0.0687192231 0.105235212 0.100469068 ... 0.0975892246 0.111664496 0.106435098]\n",
      "[0.0686112493 0.10484843 0.100132369 ... 0.0972805917 0.11120268 0.106034994]\n",
      "[0.0685037822 0.104465894 0.0997990444 ... 0.0969748646 0.110746548 0.105639368]\n",
      "[0.0683968216 0.104087517 0.0994690135 ... 0.096672006 0.110295981 0.105248146]\n",
      "[0.0682903603 0.103713222 0.0991422459 ... 0.0963719711 0.109850883 0.104861222]\n",
      "[0.0681843907 0.103342943 0.0988186747 ... 0.0960747153 0.109411128 0.10447856]\n",
      "[0.0680789128 0.102976605 0.0984982699 ... 0.0957801938 0.108976625 0.104100041]\n",
      "[0.0679739267 0.102614142 0.0981809497 ... 0.0954883695 0.108547248 0.103725612]\n",
      "[0.0678694248 0.102255471 0.0978666842 ... 0.0951991901 0.108122915 0.103355192]\n",
      "[0.0677654 0.101900555 0.0975554138 ... 0.0949126258 0.107703522 0.102988727]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=127, shape=(10,), dtype=float32, numpy=\n",
       "array([0.06766185, 0.1015493 , 0.09724709, 0.10587054, 0.10569899,\n",
       "       0.10761058, 0.10842628, 0.09462864, 0.10728898, 0.10262614],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple loop\n",
    "\n",
    "@tf.function\n",
    "def f(x):\n",
    "    while tf.reduce_sum(x) > 1:\n",
    "        tf.print(x)\n",
    "        x = tf.tanh(x)\n",
    "    return x\n",
    "\n",
    "f(tf.random.uniform([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\n",
      "\n",
      "def tf__f(x):\n",
      "  try:\n",
      "    with ag__.function_scope('f'):\n",
      "      do_return = False\n",
      "      retval_ = None\n",
      "\n",
      "      def loop_test(x_1):\n",
      "        with ag__.function_scope('loop_test'):\n",
      "          return ag__.gt(ag__.converted_call('reduce_sum', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=ag__.Feature.ALL, internal_convert_user_code=True), (x_1,), {}), 1)\n",
      "\n",
      "      def loop_body(x_1):\n",
      "        with ag__.function_scope('loop_body'):\n",
      "          with ag__.utils.control_dependency_on_returns(ag__.converted_call('print', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=ag__.Feature.ALL, internal_convert_user_code=True), (x_1,), {})):\n",
      "            x, tf_1 = ag__.utils.alias_tensors(x_1, tf)\n",
      "            x = ag__.converted_call('tanh', tf_1, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=ag__.Feature.ALL, internal_convert_user_code=True), (x,), {})\n",
      "            return x,\n",
      "      x, = ag__.while_stmt(loop_test, loop_body, (x,), (x, ag__, tf))\n",
      "      do_return = True\n",
      "      retval_ = x\n",
      "      return retval_\n",
      "  except:\n",
      "    ag__.rewrite_graph_construction_error(ag_source_map__)\n",
      "\n",
      "\n",
      "\n",
      "tf__f.autograph_info__ = {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If you're curious you can inspect the code autograph generates.\n",
    "# It feels like reading assembly language, though.\n",
    "\n",
    "def f(x):\n",
    "  while tf.reduce_sum(x) > 1:\n",
    "    tf.print(x)\n",
    "    x = tf.tanh(x)\n",
    "  return x\n",
    "\n",
    "print(tf.autograph.to_code(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-10-1aa0802c291f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-1aa0802c291f>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    for i in tf.range(10):  # depends on a tensor, we'll convert it\u001b[0m\n\u001b[1;37m                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  for i in range(10):  # Static python loop, we'll not convert it\n",
    "    do_stuff()\n",
    "  for i in tf.range(10):  # depends on a tensor, we'll convert it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=190, shape=(), dtype=int32, numpy=10240>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def f(x):\n",
    "  for i in tf.range(10):\n",
    "    tf.print(i)\n",
    "    tf.Assert(i < 10, [\"a\"])\n",
    "    x += x\n",
    "  return x\n",
    "\n",
    "f(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
